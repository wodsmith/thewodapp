---
shaping: true
---

# Team Memory System â€” Shaping

## Requirements (R)

| ID | Requirement | Status |
|----|-------------|--------|
| R0 | ðŸŸ¡ Team members can store observations from AI sessions into a shared memory â€” automatic ingestion via session hooks is primary; manual POST is fallback (self-learning system) | Core goal |
| R1 | Observations are searchable by semantic similarity (not just keyword) | Must-have |
| R2 | ðŸŸ¡ Memories condense over time (observations â†’ reflections) with decay scoring refreshed when agents find a memory useful | Must-have |
| R3 | Any team member's AI agent can retrieve relevant memories via API | Core goal |
| R4 | ðŸŸ¡ Observations have a type system â€” categories (convention, gotcha, debugging, architecture, workflow) + priority levels (critical / moderate / ephemeral) | Must-have |
| R5 | System runs entirely on Cloudflare infrastructure | Must-have |
| R6 | Lives in `/apps` within the monorepo as a standalone Worker | Must-have |
| R7 | Supports attribution â€” who observed what, from which session | Nice-to-have |
| R8 | ðŸŸ¡ Ingestion is async â€” local CLI agent (claude -p / pi -p) fires post-session, POSTs to Worker API; doesn't block the AI session | Must-have |

---

## Shape A: "D1-only flat store"

Simplest approach. D1 stores observations as rows with JSON metadata. No vector search. Full-text search via SQLite FTS5. Cron Worker does periodic condensation.

| Part | Mechanism | Flag |
|------|-----------|:----:|
| **A1** | D1 table: observations (id, userId, content, priority, metadata JSON, createdAt) | |
| **A2** | FTS5 virtual table on observation content for keyword search | |
| **A3** | Worker API: POST /observations, GET /search?q=, GET /memories | |
| **A4** | Cron Worker: daily condensation â€” LLM summarizes week's observations into reflections | âš ï¸ |
| **A5** | Reflections table in D1 storing condensed memories | |

---

## Shape B: "Full observation pipeline on CF + Lamarck reflection"

Combines joelclaw/Mastra observation pipeline (D1 + Vectorize + Workers AI) with Lamarck's maturity lifecycle and decay scoring for the reflection layer. Local CLI agents handle async ingestion.

| Part | Mechanism | Flag |
|------|-----------|:----:|
| **B1** | ðŸŸ¡ D1 tables: observations (content, category, priority, score, maturity, userId, sessionId, createdAt), reflections (condensed playbook bullets, same schema), sessions | |
| **B2** | Vectorize index with bge-small-en-v1.5 embeddings (384-dim) for semantic search | |
| **B3** | ðŸŸ¡ Workers AI: embedding generation on observation ingestion + reflection creation | |
| **B4** | ðŸŸ¡ Worker API: POST /observations, GET /search (semantic+structured), GET /context, POST /feedback | |
| **B5** | ðŸŸ¡ Lamarck-style reflection: daily Workflow condenses observations into typed playbook bullets (convention, gotcha, debugging, architecture, workflow), Jaccard dedup on ingestion | |
| **B6** | ðŸŸ¡ Maturity lifecycle: candidate â†’ established â†’ proven â†’ deprecated, auto-promote on positive feedback, deprecate when harm ratio >30% | |
| **B7** | ðŸŸ¡ Decay + refresh: exponential score decay (configurable half-life), score refresh ONLY on qualitative helpful feedback (not retrieval count), weekly staleness cron | |
| **B8** | ðŸŸ¡ Session storage: store raw session messages (user messages + key responses) in D1 for later reprocessing and querying | |
| **B9** | ðŸŸ¡ Skill interface: Claude Code skills (`/remember`, `/recall`, `/feedback`) + session hooks for automatic observation extraction â€” the client-side "frontend" | |
| **B10** | ðŸŸ¡ Core MEMORY.md promotion: auto-export proven high-score memories to a MEMORY.md loaded into every session context via `GET /export` | |

---

## Shape C: "Lamarck-style playbook with shared hosting"

Adapts Lamarck's maturity lifecycle model. Observations go through candidate â†’ established â†’ proven â†’ deprecated. Feedback loop (helpful/harmful). Category quotas. Exports team MEMORY.md.

| Part | Mechanism | Flag |
|------|-----------|:----:|
| **C1** | D1 tables: playbook_bullets (content, category, maturity, score, feedback arrays) | |
| **C2** | Ingestion: LLM extracts "diary entries" from session transcripts, generates playbook deltas | âš ï¸ |
| **C3** | Quality gates: Jaccard dedup, category quotas, scoring (decay + struggle signals) | âš ï¸ |
| **C4** | Maturity lifecycle: auto-promote on positive feedback, deprecate on harm ratio >30% | |
| **C5** | Vectorize for semantic search across playbook bullets | |
| **C6** | Worker API: POST /session-transcript, GET /playbook, POST /feedback | |
| **C7** | Cron: weekly staleness check, monthly consolidation | |
| **C8** | Export: generate team MEMORY.md from top-scored bullets per category | |

---

## Fit Check

| Req | Requirement | Status | A | B | C |
|-----|-------------|--------|---|---|---|
| R0 | Team members can store observations â€” automatic ingestion primary, manual fallback | Core goal | âœ… | âœ… | âœ… |
| R1 | Observations are searchable by semantic similarity (not just keyword) | Must-have | âŒ | âœ… | âœ… |
| R2 | Memories condense with decay scoring refreshed on agent retrieval | Must-have | âŒ | âœ… | âœ… |
| R3 | Any team member's AI agent can retrieve relevant memories via API | Core goal | âœ… | âœ… | âœ… |
| R4 | Type system â€” categories + priority levels | Must-have | âŒ | âœ… | âŒ |
| R5 | System runs entirely on Cloudflare infrastructure | Must-have | âœ… | âœ… | âœ… |
| R6 | Lives in `/apps` within the monorepo as a standalone Worker | Must-have | âœ… | âœ… | âœ… |
| R7 | Supports attribution â€” who observed what, from which session | Nice-to-have | âœ… | âœ… | âœ… |
| R8 | Ingestion is async via local CLI agent | Must-have | âœ… | âœ… | âœ… |

**Notes:**
- A fails R1: FTS5 is keyword-only, not semantic
- A fails R2: A4 condensation is flagged âš ï¸, no decay/refresh mechanism
- A fails R4: Has priority field but no category typing
- C fails R4: Has categories but no priority levels per observation
- ðŸŸ¡ R8 now passes for all shapes: async handled by local CLI agent, Worker receives POST synchronously
- ðŸŸ¡ B has zero âš ï¸ flags â€” B7 resolved with Lamarck-style reflection, old B8 (namespace isolation) removed (2-person team)
- ðŸŸ¡ Shape B renamed: "Full observation pipeline on CF + Lamarck reflection"

---

## Detail B: Concrete Affordances

Backend/API system with a skill-based "frontend." Six flows: Ingest, Search, Context, Feedback, Reflection, Decay. Skills serve as the client-side interface for AI agents.

### Places

| # | Place | Description |
|---|-------|-------------|
| P1 | Worker API | Hono router â€” HTTP surface |
| P2 | Backend | D1 + Vectorize + Workers AI + service logic |
| P3 | Reflection Workflow | Daily cron â†’ Lamarck condensation pipeline |
| P4 | Decay Cron | Weekly score decay + staleness check |
| P5 | ðŸŸ¡ Skill Interface (local) | Claude Code skills + session hooks â€” the "frontend" |

### Data Stores

| # | Place | Store | Description |
|---|-------|-------|-------------|
| S1 | P2 | `observations` (D1) | content, category, priority, score, maturity, retrievalCount, userId, sessionId, condensed, feedbackLog[], createdAt |
| S2 | P2 | `reflections` (D1) | content, category, priority, score, maturity, sourceObservationIds[], createdAt |
| S3 | P2 | `sessions` (D1) | sessionId, userId, startedAt, metadata |
| S4 | P2 | `vectorize_index` | bge-small-en-v1.5 embeddings (384-dim), type-namespaced (observation \| reflection) |
| S5 | ðŸŸ¡ P2 | `session_messages` (D1) | role, content, sessionId, createdAt â€” raw user messages + key responses for reprocessing |
| S6 | ðŸŸ¡ P5 | `MEMORY.md` (file) | Core memory file loaded into every session context â€” auto-generated from proven memories |

### Code Affordances

**P1: Worker API**

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N1 | router | `POST /observations` | call | â†’ N10, â†’ N11, â†’ N12 | â†’ caller |
| N2 | router | `GET /search` | call | â†’ N13, â†’ N14, â†’ N15 | â†’ caller |
| N3 | router | `GET /context` | call | â†’ N16 | â†’ caller |
| N4 | router | `POST /feedback` | call | â†’ N17, â†’ N18 | â†’ caller |
| N5 | ðŸŸ¡ router | `POST /sessions` | call | â†’ N35 | â†’ caller |
| N6 | ðŸŸ¡ router | `GET /export` | call | â†’ N36 | â†’ caller |

**P2: Backend**

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N10 | embedding-svc | `generateEmbedding(content)` | call | â†’ Workers AI | â†’ N11 |
| N11 | observation-svc | `storeObservation(obs, embedding)` | call | â†’ S1, â†’ S4 | â†’ N1 |
| N12 | dedup-svc | `jaccardDedup(content)` | call | â†’ S1 | â†’ N1 |
| N13 | embedding-svc | `generateEmbedding(query)` | call | â†’ Workers AI | â†’ N14 |
| N14 | search-svc | `semanticSearch(embedding, filters)` | call | â†’ S4, â†’ S1 | â†’ N2 |
| N15 | ðŸŸ¡ scoring-svc | `trackRetrieval(resultIds)` | call | â†’ S1 (retrievalCount only) | â€” |
| N16 | context-svc | `getTopContext(category?, priority?)` | call | â†’ S1, â†’ S2 | â†’ N3 |
| N17 | ðŸŸ¡ feedback-svc | `recordFeedback(id, signal, note?)` | call | â†’ S1 (score refresh on helpful, decrement on harmful) | â†’ N4 |
| N18 | maturity-svc | `checkPromotion(id)` | call | â†’ S1 | â€” |
| N35 | ðŸŸ¡ session-svc | `storeSessionMessages(messages)` | call | â†’ S5, â†’ S3 | â†’ N5 |
| N36 | ðŸŸ¡ export-svc | `exportCoreMemory(scoreThreshold)` | call | â†’ S1, â†’ S2 | â†’ N6 |

**P3: Reflection Workflow**

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N20 | cron | `dailyTrigger` | invoke | â†’ N21 | â€” |
| N21 | workflow | `queryRecentObservations()` | call | â†’ S1 | â†’ N22 |
| N22 | workflow | `condenseWithLLM(observations)` | call | â†’ Workers AI | â†’ N23 |
| N23 | workflow | `dedupReflections(bullets)` | call | â†’ S2 | â†’ N24 |
| N24 | workflow | `storeReflections(bullets)` | call | â†’ S2, â†’ S4 | â†’ N25 |
| N25 | workflow | `markCondensed(observationIds)` | call | â†’ S1 | â€” |

**P4: Decay Cron**

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N30 | cron | `weeklyTrigger` | invoke | â†’ N31 | â€” |
| N31 | decay-svc | `applyExponentialDecay(halfLife)` | call | â†’ S1, â†’ S2 | â†’ N32 |
| N32 | maturity-svc | `deprecateHarmful(harmThreshold)` | call | â†’ S1, â†’ S2 | â€” |

**P5: Skill Interface (local)**

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N40 | ðŸŸ¡ `/remember` skill | `extractAndPost(observations)` | call | â†’ N1 | â€” |
| N41 | ðŸŸ¡ `/recall` skill | `queryAndInject(taskDescription)` | call | â†’ N2 | â†’ session context |
| N42 | ðŸŸ¡ `/feedback` skill | `reportFeedback(memoryIds, signals)` | call | â†’ N4 | â€” |
| N43 | ðŸŸ¡ session-hook | `onSessionEnd()` â†’ extract obs + session messages | invoke | â†’ N1, â†’ N5 | â€” |
| N44 | ðŸŸ¡ export-hook | `syncCoreMemory()` â†’ pull latest export â†’ write MEMORY.md | invoke | â†’ N6 | â†’ S6 |
| N45 | ðŸŸ¡ session-start-hook | `injectRelevantMemories()` â†’ reads current task context (prompt, git branch, beads WIP) â†’ queries API â†’ injects into session | invoke | â†’ N2 or N3 | â†’ session context |

### Qualitative Feedback Flow

Retrieval â‰  useful. The feedback mechanism separates counting from judging:

1. **GET /search** â†’ N15 bumps `retrievalCount` only (no score change)
2. Agent uses retrieved memories during session
3. Session hook or `/feedback` skill calls **POST /feedback** with:
   - `memoryId` â€” which memory
   - `signal` â€” `helpful` | `harmful` | `irrelevant`
   - `note` â€” optional context
4. `helpful` â†’ refreshes decay score + contributes to promotion
5. `harmful` â†’ decrements score + contributes to harm ratio
6. `irrelevant` â†’ no score change, but counts toward staleness
7. When harm ratio > 30% â†’ maturity degrades toward deprecated

### Wiring Diagram

```mermaid
flowchart TB
    subgraph P5["P5: Skill Interface (local)"]
        N40["N40: /remember"]
        N41["N41: /recall"]
        N42["N42: /feedback"]
        N43["N43: session-hook"]
        N44["N44: export-hook"]
        N45["N45: session-start-hook"]
        S6["S6: MEMORY.md"]
    end

    subgraph P1["P1: Worker API"]
        N1["N1: POST /observations"]
        N2["N2: GET /search"]
        N3["N3: GET /context"]
        N4["N4: POST /feedback"]
        N5["N5: POST /sessions"]
        N6["N6: GET /export"]
    end

    subgraph P2["P2: Backend"]
        N10["N10: generateEmbedding"]
        N11["N11: storeObservation"]
        N12["N12: jaccardDedup"]
        N14["N14: semanticSearch"]
        N15["N15: trackRetrieval"]
        N16["N16: getTopContext"]
        N17["N17: recordFeedback"]
        N18["N18: checkPromotion"]
        N35["N35: storeSessionMessages"]
        N36["N36: exportCoreMemory"]

        S1["S1: observations"]
        S2["S2: reflections"]
        S4["S4: vectorize_index"]
        S5["S5: session_messages"]
    end

    subgraph P3["P3: Reflection Workflow"]
        N20["N20: dailyTrigger"]
        N21["N21: queryRecentObs"]
        N22["N22: condenseWithLLM"]
        N23["N23: dedupReflections"]
        N24["N24: storeReflections"]
        N25["N25: markCondensed"]
    end

    subgraph P4["P4: Decay Cron"]
        N30["N30: weeklyTrigger"]
        N31["N31: applyDecay"]
        N32["N32: deprecateHarmful"]
    end

    %% Skill â†’ API wiring
    N40 --> N1
    N41 --> N2
    N42 --> N4
    N43 --> N1
    N43 --> N5
    N44 --> N6
    N6 -.-> N44
    N44 -.-> S6
    N45 --> N2
    N45 --> N3

    %% Ingestion flow
    N1 --> N10
    N1 --> N12
    N10 -.-> N11
    N11 --> S1
    N11 --> S4
    N12 --> S1

    %% Session storage
    N5 --> N35
    N35 --> S5

    %% Search flow
    N2 --> N14
    N14 --> S4
    N14 -.-> S1
    N14 -.-> N2
    N2 --> N15
    N15 --> S1

    %% Context flow
    N3 --> N16
    N16 --> S1
    N16 --> S2

    %% Feedback flow (qualitative)
    N4 --> N17
    N17 --> S1
    N4 --> N18
    N18 --> S1

    %% Export flow
    N6 --> N36
    N36 --> S1
    N36 --> S2

    %% Reflection flow
    N20 --> N21
    N21 --> S1
    N21 -.-> N22
    N22 -.-> N23
    N23 --> S2
    N24 --> S2
    N24 --> S4
    N25 --> S1

    %% Decay flow
    N30 --> N31
    N31 --> S1
    N31 --> S2
    N31 -.-> N32
    N32 --> S1
    N32 --> S2

    classDef api fill:#ffb6c1,stroke:#d87093,color:#000
    classDef svc fill:#d3d3d3,stroke:#808080,color:#000
    classDef store fill:#e6e6fa,stroke:#9370db,color:#000
    classDef workflow fill:#90EE90,stroke:#228B22,color:#000
    classDef skill fill:#b3e5fc,stroke:#0288d1,color:#000

    class N1,N2,N3,N4,N5,N6 api
    class N10,N11,N12,N14,N15,N16,N17,N18,N35,N36 svc
    class S1,S2,S4,S5,S6 store
    class N20,N21,N22,N23,N24,N25,N30,N31,N32 workflow
    class N40,N41,N42,N43,N44,N45 skill
```

---

## Slicing

### Slice Summary

| # | Slice | Parts | Affordances | Demo |
|---|-------|-------|-------------|------|
| V1 | Worker + Ingestion | B1, B2, B3, B4 (partial) | N1, N10, N11, N12, S1, S3, S4 | `curl POST /observations` â†’ stored in D1 + Vectorize |
| V2 | Semantic Search | B2, B4 (partial) | N2, N13, N14, N15 | `POST` a gotcha, then `GET /search` finds it by meaning |
| V3 | Context + Export | B4 (partial), B10 | N3, N16, N6, N36, S6 | `GET /context` returns top memories; `GET /export` emits MEMORY.md |
| V4 | Feedback + Maturity | B6, B7 (partial) | N4, N17, N18 | `POST /feedback` helpful â†’ score refreshes, maturity promotes |
| V5 | Skills + Session Hooks | B8, B9 | N5, N35, N40â€“N45, S5 | `/remember` in Claude Code stores obs; session-start-hook auto-injects |
| V6 | Reflection + Decay | B5, B7 (partial) | N20â€“N25, N30â€“N32, S2 | Daily cron condenses observations â†’ reflections appear in `/context` |

---

### V1: Worker + Ingestion

Scaffold the Hono Worker in `/apps/team-memory`, create D1 tables, Vectorize index, and the ingestion endpoint. This is the foundation everything else builds on.

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N1 | router | `POST /observations` | call | â†’ N10, â†’ N11, â†’ N12 | â†’ caller |
| N10 | embedding-svc | `generateEmbedding(content)` | call | â†’ Workers AI | â†’ N11 |
| N11 | observation-svc | `storeObservation(obs, embedding)` | call | â†’ S1, â†’ S4 | â†’ N1 |
| N12 | dedup-svc | `jaccardDedup(content)` | call | â†’ S1 | â†’ N1 |

**Stores created:** S1 (`observations`), S3 (`sessions`), S4 (`vectorize_index`)

**Demo:** `curl -X POST /observations -d '{"content":"PlanetScale returns strings for COUNT","category":"gotcha","priority":"critical"}'` â†’ 201 with stored observation ID

---

### V2: Semantic Search

Add the search endpoint. Embed the query, search Vectorize for nearest neighbors, hydrate from D1, track retrieval count (no score change).

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N2 | router | `GET /search` | call | â†’ N13, â†’ N14, â†’ N15 | â†’ caller |
| N13 | embedding-svc | `generateEmbedding(query)` | call | â†’ Workers AI | â†’ N14 |
| N14 | search-svc | `semanticSearch(embedding, filters)` | call | â†’ S4, â†’ S1 | â†’ N2 |
| N15 | scoring-svc | `trackRetrieval(resultIds)` | call | â†’ S1 | â€” |

**Demo:** Store 3 observations, then `GET /search?q=database type coercion` returns the PlanetScale gotcha first by semantic similarity.

---

### V3: Context + Export

Add context retrieval (top memories by category/priority) and export (MEMORY.md generation from proven high-score memories).

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N3 | router | `GET /context` | call | â†’ N16 | â†’ caller |
| N16 | context-svc | `getTopContext(category?, priority?)` | call | â†’ S1, â†’ S2 | â†’ N3 |
| N6 | router | `GET /export` | call | â†’ N36 | â†’ caller |
| N36 | export-svc | `exportCoreMemory(scoreThreshold)` | call | â†’ S1, â†’ S2 | â†’ N6 |

**Store created:** S6 (`MEMORY.md` file â€” consumed downstream by V5)

**Demo:** `GET /context?category=gotcha` returns ranked gotchas. `GET /export` produces markdown ready for MEMORY.md injection.

---

### V4: Feedback + Maturity

Add the feedback endpoint. Qualitative signals (helpful/harmful/irrelevant) drive score changes and maturity transitions.

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N4 | router | `POST /feedback` | call | â†’ N17, â†’ N18 | â†’ caller |
| N17 | feedback-svc | `recordFeedback(id, signal, note?)` | call | â†’ S1 | â†’ N4 |
| N18 | maturity-svc | `checkPromotion(id)` | call | â†’ S1 | â€” |

**Demo:** Store an observation (candidate). `POST /feedback {signal: "helpful"}` x3 â†’ observation promotes to "established." Verify with `GET /search` showing updated maturity.

---

### V5: Skills + Session Hooks

Build the Claude Code skill files and session hooks. This is the "frontend" â€” how agents actually interact with the memory system day-to-day.

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N5 | router | `POST /sessions` | call | â†’ N35 | â†’ caller |
| N35 | session-svc | `storeSessionMessages(messages)` | call | â†’ S5, â†’ S3 | â†’ N5 |
| N40 | `/remember` skill | `extractAndPost(observations)` | call | â†’ N1 | â€” |
| N41 | `/recall` skill | `queryAndInject(taskDescription)` | call | â†’ N2 | â†’ session context |
| N42 | `/feedback` skill | `reportFeedback(memoryIds, signals)` | call | â†’ N4 | â€” |
| N43 | session-hook | `onSessionEnd()` | invoke | â†’ N1, â†’ N5 | â€” |
| N44 | export-hook | `syncCoreMemory()` | invoke | â†’ N6 | â†’ S6 |
| N45 | session-start-hook | `injectRelevantMemories()` | invoke | â†’ N2 or N3 | â†’ session context |

**Store created:** S5 (`session_messages`)

**Demo:** In a Claude Code session, run `/remember "Always use Number() for PlanetScale counts"` â†’ observation stored. Start a new session â†’ session-start-hook auto-injects relevant memories.

---

### V6: Reflection + Decay

Add the automated maintenance layer. Daily reflection workflow condenses observations. Weekly decay cron ages out stale memories.

| # | Component | Affordance | Control | Wires Out | Returns To |
|---|-----------|------------|---------|-----------|------------|
| N20 | cron | `dailyTrigger` | invoke | â†’ N21 | â€” |
| N21 | workflow | `queryRecentObservations()` | call | â†’ S1 | â†’ N22 |
| N22 | workflow | `condenseWithLLM(observations)` | call | â†’ Workers AI | â†’ N23 |
| N23 | workflow | `dedupReflections(bullets)` | call | â†’ S2 | â†’ N24 |
| N24 | workflow | `storeReflections(bullets)` | call | â†’ S2, â†’ S4 | â†’ N25 |
| N25 | workflow | `markCondensed(observationIds)` | call | â†’ S1 | â€” |
| N30 | cron | `weeklyTrigger` | invoke | â†’ N31 | â€” |
| N31 | decay-svc | `applyExponentialDecay(halfLife)` | call | â†’ S1, â†’ S2 | â†’ N32 |
| N32 | maturity-svc | `deprecateHarmful(harmThreshold)` | call | â†’ S1, â†’ S2 | â€” |

**Store created:** S2 (`reflections`)

**Demo:** Seed 20+ observations across categories. Trigger daily workflow manually â†’ reflections appear in `GET /context`. Trigger weekly decay â†’ scores drop, deprecated items disappear from export.